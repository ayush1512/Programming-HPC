{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911842ca",
   "metadata": {},
   "source": [
    "### Solved examples (for reference to solve assignment \"PythonPart2 G Assignments_08Oct2025.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e9d510",
   "metadata": {},
   "source": [
    "# 1. Serialization using JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f86e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Converts Python data ↔ JSON text (cross-platform format).\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Serialized JSON:\n",
      " {\n",
      "    \"name\": \"Alice\",\n",
      "    \"id\": 101,\n",
      "    \"dept\": \"R&D\",\n",
      "    \"skills\": [\n",
      "        \"Python\",\n",
      "        \"ML\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "Deserialized Object:\n",
      " {'name': 'Alice', 'id': 101, 'dept': 'R&D', 'skills': ['Python', 'ML']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Concept: Converts Python data ↔ JSON text (cross-platform format).\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# Python object\n",
    "employee = {\n",
    "    \"name\": \"Alice\",\n",
    "    \"id\": 101,\n",
    "    \"dept\": \"R&D\",\n",
    "    \"skills\": [\"Python\", \"ML\"]\n",
    "}\n",
    "\n",
    "# Serialize to JSON string\n",
    "json_str = json.dumps(employee, indent=4)\n",
    "print(\"Serialized JSON:\\n\", json_str)\n",
    "\n",
    "# Deserialize back to Python object\n",
    "emp_obj = json.loads(json_str)\n",
    "print(\"\\nDeserialized Object:\\n\", emp_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e31e32",
   "metadata": {},
   "source": [
    "# 2. Serialization using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43161f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Binary serialization (Python-specific).\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Pickled & Loaded Object: {'a': 10, 'b': [1, 2, 3]}\n",
      "type(loaded) : <class 'dict'>\n",
      "type(loaded) : <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Concept: Binary serialization (Python-specific).\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "import pickle\n",
    "\n",
    "data = {\"a\": 10, \"b\": [1, 2, 3]}\n",
    "\n",
    "# Serialize (dump) to file\n",
    "with open(\"data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "# Deserialize (load) from file\n",
    "with open(\"data.pkl\", \"rb\") as f:\n",
    "    loaded = pickle.load(f)\n",
    "\n",
    "print(\"Pickled & Loaded Object:\", loaded)\n",
    "print(\"type(loaded) :\", type(loaded) )\n",
    "print(\"type(loaded) :\", type(loaded) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa61ef-93e1-42a8-a80f-7355ad3d2ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9365d0e0",
   "metadata": {},
   "source": [
    "# 3. Multiprocessing – Running Two Simple Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ad0e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Each process runs independently in its own memory space.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Both processes complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Concept: Each process runs independently in its own memory space.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "\n",
    "from multiprocessing import Process\n",
    "import os, time\n",
    "\n",
    "def worker(name):\n",
    "    print(f\"{name} running in PID {os.getpid()}\")\n",
    "    time.sleep(1)\n",
    "    print(f\"{name} finished\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p1 = Process(target=worker, args=(\"Process-1\",))\n",
    "    p2 = Process(target=worker, args=(\"Process-2\",))\n",
    "    p1.start(); p2.start()\n",
    "    p1.join();  p2.join()\n",
    "    print(\"Both processes complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ed023",
   "metadata": {},
   "source": [
    "# 4. Multiprocessing – Using Pool and Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038aa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Pool distributes tasks across worker processes.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print(\"Concept: Pool distributes tasks across worker processes.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def square(x): \n",
    "    return x * x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(processes=4) as pool:\n",
    "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
    "    print(\"Squares:\", results)\n",
    "'''\n",
    "\n",
    "'''\n",
    "Problem: Error: Kernel-hangs: Executes infinitely in jupyter notebook, so try this example in .py file\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8127226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Pool distributes tasks across worker threads. This works perfectly in Jupyter since it uses threads, not processes — no kernel hang.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Concept: Pool distributes tasks across worker threads. This works perfectly in Jupyter since it uses threads, not processes — no kernel hang.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "from multiprocessing.dummy import Pool  # uses threads instead of processes\n",
    "\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "pool = Pool(4)\n",
    "print(pool.map(square, [1, 2, 3, 4, 5]))\n",
    "pool.close()\n",
    "pool.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17baaf7c",
   "metadata": {},
   "source": [
    "# 5. Basics of Multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f10dc810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Lightweight concurrency in same memory space.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Hello A\n",
      "Hello B\n",
      "Bye ABye B\n",
      "\n",
      "Threads finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Concept: Lightweight concurrency in same memory space.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "import threading, time\n",
    "\n",
    "def greet(name):\n",
    "    print(f\"Hello {name}\")\n",
    "    time.sleep(1)\n",
    "    print(f\"Bye {name}\")\n",
    "\n",
    "t1 = threading.Thread(target=greet, args=(\"A\",))\n",
    "t2 = threading.Thread(target=greet, args=(\"B\",))\n",
    "t1.start(); t2.start()\n",
    "t1.join();  t2.join()\n",
    "print(\"Threads finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d270586a",
   "metadata": {},
   "source": [
    "# 6. Communicating Between Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a2000a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Use queue.Queue for thread-safe data exchange.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Produced: 0\n",
      "Produced: 1\n",
      "Consumed: 0Produced:\n",
      "Consumed: 1\n",
      "Consumed: 2\n",
      " 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Concept: Use queue.Queue for thread-safe data exchange.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "import threading, queue\n",
    "\n",
    "def producer(q):\n",
    "    for i in range(3):\n",
    "        q.put(i)\n",
    "        print(\"Produced:\", i)\n",
    "\n",
    "def consumer(q):\n",
    "    while True:\n",
    "        item = q.get()\n",
    "        if item is None: break\n",
    "        print(\"Consumed:\", item)\n",
    "\n",
    "q = queue.Queue()\n",
    "t1 = threading.Thread(target=producer, args=(q,))\n",
    "t2 = threading.Thread(target=consumer, args=(q,))\n",
    "t1.start(); t2.start()\n",
    "t1.join(); q.put(None)\n",
    "t2.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218b19d4",
   "metadata": {},
   "source": [
    "# 7. Creating a Worker Pool (Threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf53f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: ThreadPoolExecutor simplifies worker thread management.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Concept: ThreadPoolExecutor simplifies worker thread management.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "import concurrent.futures, time\n",
    "\n",
    "def task(n):\n",
    "    time.sleep(1)\n",
    "    return n * n\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    results = executor.map(task, [1, 2, 3, 4, 5])\n",
    "\n",
    "print(list(results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cb9360",
   "metadata": {},
   "source": [
    "# 8. Stoppable Thread with a While Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b13f4395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Use Event flag to gracefully stop threads.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Working...\n",
      "Stopped!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Concept: Use Event flag to gracefully stop threads.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "import threading, time\n",
    "\n",
    "stop_event = threading.Event()\n",
    "\n",
    "def worker():\n",
    "    while not stop_event.is_set():\n",
    "        print(\"Working...\")\n",
    "        time.sleep(0.5)\n",
    "    print(\"Stopped!\")\n",
    "\n",
    "t = threading.Thread(target=worker)\n",
    "t.start()\n",
    "time.sleep(2)\n",
    "stop_event.set()\n",
    "t.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc716320",
   "metadata": {},
   "source": [
    "# 9. Global Interpreter Lock (GIL) Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217d66b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Threads share same GIL → true parallel CPU execution not achieved.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Final Count: 1292846\n",
      "Time Taken: 0.215745210647583\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(\"Concept: Threads share same GIL → true parallel CPU execution not achieved.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "\n",
    "import threading, time\n",
    "\n",
    "count = 0\n",
    "def increment():\n",
    "    global count\n",
    "    for _ in range(1000000):\n",
    "        count += 1\n",
    "\n",
    "t1 = threading.Thread(target=increment)\n",
    "t2 = threading.Thread(target=increment)\n",
    "start = time.time()\n",
    "t1.start(); t2.start()\n",
    "t1.join(); t2.join()\n",
    "print(\"Final Count:\", count)\n",
    "print(\"Time Taken:\", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814a53d0-055d-4e21-9b58-52d1153b31c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Threads share same GIL → true parallel CPU execution not achieved.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Final Count: 2000000\n",
      "Time Taken: 0.9417767524719238\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(\"Concept: Threads share same GIL → true parallel CPU execution not achieved.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "\n",
    "import threading, time\n",
    "\n",
    "# Note : Always bind Resource and lock together, unlike below global\n",
    "count = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def increment():\n",
    "    global count\n",
    "    for _ in range(1000000):\n",
    "        with lock:\n",
    "            count += 1\n",
    "        # lock.unlock()\n",
    "\n",
    "t1 = threading.Thread(target=increment)\n",
    "t2 = threading.Thread(target=increment)\n",
    "start = time.time()\n",
    "t1.start(); t2.start()\n",
    "t1.join(); t2.join()\n",
    "print(\"Final Count:\", count)\n",
    "print(\"Time Taken:\", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eefe1a-8149-4e28-b1ed-a826ac076a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6de2108a",
   "metadata": {},
   "source": [
    "# 10. Running in Multiple Threads vs Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27712599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: CPU-bound → faster with multiprocessing (bypasses GIL).\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Threads Time: 0.6019420623779297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Concept: CPU-bound → faster with multiprocessing (bypasses GIL).\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from threading import Thread\n",
    "\n",
    "def compute(n):\n",
    "    return sum(i*i for i in range(n))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Thread version\n",
    "    start = time.time()\n",
    "    threads = [Thread(target=compute, args=(10_000_00,)) for _ in range(4)]\n",
    "    for t in threads: t.start()\n",
    "    for t in threads: t.join()\n",
    "    print(\"Threads Time:\", time.time()-start)\n",
    "\n",
    "    # Process version\n",
    "    start = time.time()\n",
    "    with Pool(4) as pool:\n",
    "        pool.map(compute, [10_000_00]*4)\n",
    "    print(\"Processes Time:\", time.time()-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ae149e",
   "metadata": {},
   "source": [
    "# 11. Sharing State Between Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc852bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Locks ensure safe access to shared variables.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Shared data (threads): 5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Concept: Locks ensure safe access to shared variables.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "import threading\n",
    "\n",
    "shared_data = 0\n",
    "lock = threading.Lock()\n",
    "\n",
    "def update():\n",
    "    global shared_data\n",
    "    for _ in range(1000):\n",
    "        with lock:\n",
    "            shared_data += 1\n",
    "\n",
    "threads = [threading.Thread(target=update) for _ in range(5)]\n",
    "for t in threads: t.start()\n",
    "for t in threads: t.join()\n",
    "print(\"Shared data (threads):\", shared_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049057df",
   "metadata": {},
   "source": [
    "# 12. Sharing State Between Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75da6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: Use multiprocessing.Value, Array, or Manager for shared state.\n",
      "+- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- +- \n",
      "Shared number (processes): 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "\n",
    "print(\"Concept: Use multiprocessing.Value, Array, or Manager for shared state.\")\n",
    "print(\"+- \"*25)\n",
    "\n",
    "\n",
    "from multiprocessing import Process, Value, Lock\n",
    "\n",
    "def add_100(num, lock):\n",
    "    for _ in range(100):\n",
    "        with lock:\n",
    "            num.value += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    number = Value('i', 0)\n",
    "    lock = Lock()\n",
    "    processes = [Process(target=add_100, args=(number, lock)) for _ in range(5)]\n",
    "    for p in processes: p.start()\n",
    "    for p in processes: p.join()\n",
    "    print(\"Shared number (processes):\", number.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d95c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cbf09be",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1753c33",
   "metadata": {},
   "source": [
    "## Question by student . What's Differences Between Serialization vs Pickle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ec448a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serialization (Generic)</th>\n",
       "      <th>Pickle (Python-specific)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Definition</th>\n",
       "      <td>Concept of converting objects to transferable ...</td>\n",
       "      <td>A specific Python module for serializing objects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Format</th>\n",
       "      <td>Can be text (JSON/XML) or binary</td>\n",
       "      <td>Binary format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portability</th>\n",
       "      <td>Cross-language compatible (e.g., JSON works in...</td>\n",
       "      <td>Works only in Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Serialization (Generic)  \\\n",
       "Feature                                                          \n",
       "Definition   Concept of converting objects to transferable ...   \n",
       "Format                        Can be text (JSON/XML) or binary   \n",
       "Portability  Cross-language compatible (e.g., JSON works in...   \n",
       "\n",
       "                                     Pickle (Python-specific)  \n",
       "Feature                                                        \n",
       "Definition   A specific Python module for serializing objects  \n",
       "Format                                          Binary format  \n",
       "Portability                              Works only in Python  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to hold your data\n",
    "data = {\n",
    "    'Feature': ['Definition', 'Format', 'Portability'] ,# 'Readability', 'Security', 'Typical Usage'],\n",
    "    'Serialization (Generic)': ['Concept of converting objects to transferable format', 'Can be text (JSON/XML) or binary', 'Cross-language compatible (e.g., JSON works in JS, Java, etc.)'],\n",
    "    'Pickle (Python-specific)': ['A specific Python module for serializing objects', 'Binary format', 'Works only in Python']\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data).set_index('Feature')\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328d69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31555f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7539a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
